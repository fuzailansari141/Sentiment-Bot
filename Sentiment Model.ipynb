{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f41e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas library, which is commonly used for data manipulation and analysis.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ad1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv file and storing it in a dataframe\n",
    "df=pd.read_csv("Data.csv")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cf450ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good for the goose</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the gander , some of which occasionally amuses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amuses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76473</th>\n",
       "      <td>quietly suggesting the sadness and obsession b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76474</th>\n",
       "      <td>sadness and obsession</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76475</th>\n",
       "      <td>sadness and</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76476</th>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76477</th>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76478 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  Sentiment\n",
       "0      A series of escapades demonstrating the adage ...          0\n",
       "1                                     good for the goose          1\n",
       "2                                                   good          1\n",
       "3      the gander , some of which occasionally amuses...          0\n",
       "4                                                 amuses          1\n",
       "...                                                  ...        ...\n",
       "76473  quietly suggesting the sadness and obsession b...          0\n",
       "76474                              sadness and obsession          0\n",
       "76475                                        sadness and          0\n",
       "76476                          forced avuncular chortles          0\n",
       "76477                                 avuncular chortles          1\n",
       "\n",
       "[76478 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea40030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76478 entries, 0 to 76477\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       76478 non-null  object\n",
      " 1   Sentiment  76478 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Checking all the information \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd8905e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    42133\n",
       "0    34345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting particulars of target column\n",
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bfc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the NLTK (Natural Language Toolkit) library for natural language processing tasks.\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d933ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 're' module, which provides support for regular expressions in Python.\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c49e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading the NLTK \"stopwords\" dataset, which contains common stopwords in various languages.\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9d24a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'PorterStemmer' class from the 'nltk.stem' module.\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4f1014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a PorterStemmer object\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e178c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a set of English stopwords using NLTK\n",
    "stopwords=set(nltk.corpus.stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce41b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for cleaning and preprocessing text\n",
    "def clean(text):\n",
    "    # Removing newline and tab characters\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"\\t\", \"\")\n",
    "    \n",
    "    # Defining a regular expression pattern to remove emojis\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U0001F004-\\U0001F0CF\"  # Miscellaneous Symbols and Arrows\n",
    "        \"\\U0001F170-\\U0001F251\"  # Enclosed Characters\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE,\n",
    "    )\n",
    "    # Using sub() method to replace emojis with an empty string\n",
    "    text_without_emojis = emoji_pattern.sub(r\"\", text)\n",
    "    \n",
    "    # Defining a regular expression pattern to match symbols, signs, and operators\n",
    "    pattern = r'[!@#$%^&*()_+={}\\[\\]:;\"\\'<>,.?/\\|\\\\`~]'\n",
    "\n",
    "    # Using the re.sub() function to remove the matched characters\n",
    "    cleaned_string = re.sub(pattern, '', text_without_emojis)\n",
    "    \n",
    "    # Converting text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    terms = text.split(\" \")\n",
    "    \n",
    "    # Remove stopwords\n",
    "    terms = [t for t in terms if t not in stopwords]\n",
    "    \n",
    "    # Stem the words using Porter Stemmer\n",
    "    terms = [stemmer.stem(t) for t in terms]\n",
    "    \n",
    "    # Join the cleaned terms back into a string\n",
    "    clean_text = \" \".join(terms)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74ce4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'Clean_text' in the DataFrame 'df' by applying the 'clean' function to each element in the 'text' column.\n",
    "df['Clean_text']=df['text'].apply(lambda x:clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "889bf8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>0</td>\n",
       "      <td>seri escapad demonstr adag good goos also good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good for the goose</td>\n",
       "      <td>1</td>\n",
       "      <td>good goos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the gander , some of which occasionally amuses...</td>\n",
       "      <td>0</td>\n",
       "      <td>gander , occasion amus none amount much stori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amuses</td>\n",
       "      <td>1</td>\n",
       "      <td>amus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76473</th>\n",
       "      <td>quietly suggesting the sadness and obsession b...</td>\n",
       "      <td>0</td>\n",
       "      <td>quietli suggest sad obsess beneath hearst 's f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76474</th>\n",
       "      <td>sadness and obsession</td>\n",
       "      <td>0</td>\n",
       "      <td>sad obsess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76475</th>\n",
       "      <td>sadness and</td>\n",
       "      <td>0</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76476</th>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>0</td>\n",
       "      <td>forc avuncular chortl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76477</th>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>avuncular chortl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76478 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  Sentiment   \n",
       "0      A series of escapades demonstrating the adage ...          0  \\\n",
       "1                                     good for the goose          1   \n",
       "2                                                   good          1   \n",
       "3      the gander , some of which occasionally amuses...          0   \n",
       "4                                                 amuses          1   \n",
       "...                                                  ...        ...   \n",
       "76473  quietly suggesting the sadness and obsession b...          0   \n",
       "76474                              sadness and obsession          0   \n",
       "76475                                        sadness and          0   \n",
       "76476                          forced avuncular chortles          0   \n",
       "76477                                 avuncular chortles          1   \n",
       "\n",
       "                                              Clean_text  \n",
       "0      seri escapad demonstr adag good goos also good...  \n",
       "1                                              good goos  \n",
       "2                                                   good  \n",
       "3          gander , occasion amus none amount much stori  \n",
       "4                                                   amus  \n",
       "...                                                  ...  \n",
       "76473  quietli suggest sad obsess beneath hearst 's f...  \n",
       "76474                                         sad obsess  \n",
       "76475                                                sad  \n",
       "76476                              forc avuncular chortl  \n",
       "76477                                   avuncular chortl  \n",
       "\n",
       "[76478 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e3d8506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating feature and target\n",
    "x=df['Clean_text']\n",
    "y=df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b48858a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'TfidfVectorizer' class from the 'sklearn.feature_extraction.text' module for text feature extraction.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ed599a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the 'TfidfVectorizer' class, which can be used for text feature extraction.\n",
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f33f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'TfidfVectorizer' instance 'vect' to transform the text data 'x' into a TF-IDF matrix.\n",
    "x = vect.fit_transform(x.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05cbcb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'train_test_split' function from the 'sklearn.model_selection' module for dataset splitting.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38361f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbffb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'MultinomialNB' class from the 'sklearn.naive_bayes' module for Naive Bayes classification.\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaece6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the 'MultinomialNB' class and assign it to the variable 'model1'.\n",
    "model1 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e447875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the 'model1' (Multinomial Naive Bayes classifier) on the training data.\n",
    "model1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f3099ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the trained 'model1' (Multinomial Naive Bayes classifier) to make predictions on both the training and testing data.\n",
    "\n",
    "# Predictions on the training data\n",
    "y_pred_train = model1.predict(x_train)\n",
    "\n",
    "# Predictions on the testing data\n",
    "y_pred_test = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f4ac3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing accuracy_score from sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02d8f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Training Data: 0.8831355627472133\n"
     ]
    }
   ],
   "source": [
    "# Calculating and printing the accuracy score for training data\n",
    "print(\"Accuracy of Training Data:\",accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3da83004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Testing Data: 0.8604210251046025\n"
     ]
    }
   ],
   "source": [
    "# Calculating and printing the accuracy score for testing data\n",
    "print(\"Accuracy of Testing Data:\",accuracy_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "762fb732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Training Data:\n",
      "[[22922  4436]\n",
      " [ 2714 31110]]\n",
      "\n",
      "Confusion Matrix for Testing Data:\n",
      "[[5695 1292]\n",
      " [ 843 7466]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix for the training data\n",
    "confusion_matrix_train = confusion_matrix(y_train, y_pred_train)\n",
    "\n",
    "# Confusion matrix for the testing data\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "# Print the confusion matrices\n",
    "print(\"Confusion Matrix for Training Data:\")\n",
    "print(confusion_matrix_train)\n",
    "print(\"\\nConfusion Matrix for Testing Data:\")\n",
    "print(confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d982206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: really do a great job of anchoring the characters in the emotional realities of middle age .\n",
      "Predicted Label: Positive\n",
      "\n",
      "Text: water torture\n",
      "Predicted Label: Negative\n",
      "\n",
      "Text: of unfocused , excruciatingly tedious cinema\n",
      "Predicted Label: Negative\n",
      "\n",
      "Text: It makes you believe the cast and crew thoroughly enjoyed themselves and believed in their small-budget film .\n",
      "Predicted Label: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the model prediction\n",
    "new_text = [\"really do a great job of anchoring the characters in the emotional realities of middle age .\",\"water torture\",\"of unfocused , excruciatingly tedious cinema\",\"It makes you believe the cast and crew thoroughly enjoyed themselves and believed in their small-budget film .\"]\n",
    "# Preprocess the new text (clean, tokenize, and vectorize)\n",
    "new_text_vectorized = vect.transform(new_text)  # 'vect' is your TfidfVectorizer\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "new_text_predictions = model1.predict(new_text_vectorized)\n",
    "\n",
    "# Display the predictions\n",
    "for text, prediction in zip(new_text, new_text_predictions):\n",
    "    print(f\"Text: {text}\")\n",
    "    if prediction==1:\n",
    "        print(f\"Predicted Label: Positive\\n\")\n",
    "    else:\n",
    "        print(f\"Predicted Label: Negative\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c35f2539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed \n",
    "import joblib \n",
    "\n",
    "\n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(model1, 'xyz.pkl') \n",
    "joblib.dump(vect, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "753a918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: really do a great job of anchoring the characters in the emotional realities of middle age .\n",
      "Predicted Label: Positive\n",
      "\n",
      "Text: water torture\n",
      "Predicted Label: Negative\n",
      "\n",
      "Text: of unfocused , excruciatingly tedious cinema\n",
      "Predicted Label: Negative\n",
      "\n",
      "Text: It makes you believe the cast and crew thoroughly enjoyed themselves and believed in their small-budget film .\n",
      "Predicted Label: Positive\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fuzail Ansari\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MultinomialNB from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file \n",
    "model= joblib.load('xyz.pkl') \n",
    "\n",
    "#Checking the model prediction\n",
    "new_text = [\"really do a great job of anchoring the characters in the emotional realities of middle age .\",\"water torture\",\"of unfocused , excruciatingly tedious cinema\",\"It makes you believe the cast and crew thoroughly enjoyed themselves and believed in their small-budget film .\"]\n",
    "# Preprocess the new text (clean, tokenize, and vectorize)\n",
    "new_text_vectorized = vect.transform(new_text)  # 'vect' is your TfidfVectorizer\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "new_text_predictions = model.predict(new_text_vectorized)\n",
    "\n",
    "# Display the predictions\n",
    "for text, prediction in zip(new_text, new_text_predictions):\n",
    "    print(f\"Text: {text}\")\n",
    "    if prediction==1:\n",
    "        print(f\"Predicted Label: Positive\\n\")\n",
    "    else:\n",
    "        print(f\"Predicted Label: Negative\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
